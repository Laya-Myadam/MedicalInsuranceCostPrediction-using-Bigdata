# -*- coding: utf-8 -*-
"""Medical-cost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YXKv3StzvTgJap12iZFTYK5rCsTgXzd7
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.regression import LinearRegression
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import RegressionEvaluator
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize Spark Session
spark = SparkSession.builder \
    .appName("InsurancePrediction") \
    .getOrCreate()

# Load the data
insurance_df = spark.read.csv('/home/hadoop/insurance.csv', header=True, inferSchema=True)

# Display first few rows and schema info
print("First few rows of the dataset:")
insurance_df.show(5)
print("\nDataset Schema:")
insurance_df.printSchema()

# Convert categorical variables using StringIndexer
sex_indexer = StringIndexer(inputCol="sex", outputCol="sex_indexed")
smoker_indexer = StringIndexer(inputCol="smoker", outputCol="smoker_indexed")
region_indexer = StringIndexer(inputCol="region", outputCol="region_indexed")

# Create feature vector
feature_cols = ['age', 'sex_indexed', 'bmi', 'children', 'smoker_indexed', 'region_indexed']
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

# Create pipeline for preprocessing
preprocessing_pipeline = Pipeline(stages=[sex_indexer, smoker_indexer, region_indexer, assembler])

# Split the data
(training_data, test_data) = insurance_df.randomSplit([0.8, 0.2], seed=2)

# Fit the pipeline on training data
preprocessing_model = preprocessing_pipeline.fit(training_data)

# Transform both training and test data
training_transformed = preprocessing_model.transform(training_data)
test_transformed = preprocessing_model.transform(test_data)

# Initialize and train Linear Regression model
lr = LinearRegression(featuresCol="features", labelCol="charges")
lr_model = lr.fit(training_transformed)

# Make predictions
training_predictions = lr_model.transform(training_transformed)
test_predictions = lr_model.transform(test_transformed)

# Evaluate the model
evaluator = RegressionEvaluator(labelCol="charges", predictionCol="prediction", metricName="r2")
train_r2 = evaluator.evaluate(training_predictions)
test_r2 = evaluator.evaluate(test_predictions)

print("\nModel Performance:")
print(f"R-squared on training data: {train_r2:.4f}")
print(f"R-squared on test data: {test_r2:.4f}")

# Cleanup
spark.stop()

